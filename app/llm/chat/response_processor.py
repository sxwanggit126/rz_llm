"""
å“åº”å¤„ç†å™¨ - æ¸…ç†å’Œè§„èŒƒåŒ–æ¨¡å‹è¾“å‡º
"""
import re
from typing import Tuple, Optional
from app.utils.logger import get_logger

logger = get_logger("ResponseProcessor")


class ThinkTagProcessor:
    """å¤„ç†<think>æ ‡ç­¾çš„å·¥å…·ç±»"""

    @classmethod
    def clean_duplicate_think_tags(cls, content: str) -> str:
        """
        æ¸…ç†é‡å¤çš„<think>æ ‡ç­¾

        å¤„ç†åœºæ™¯ï¼š
        1. reasoning_contentäº§ç”Ÿçš„<think>æ ‡ç­¾
        2. æ¨¡å‹å“åº”promptè¦æ±‚äº§ç”Ÿçš„<think>æ ‡ç­¾
        """
        # ç»Ÿè®¡<think>æ ‡ç­¾æ•°é‡
        think_open_count = content.count("<think>")
        think_close_count = content.count("</think>")

        logger.debug(f"Found {think_open_count} <think> tags and {think_close_count} </think> tags")

        if think_open_count <= 1 and think_close_count <= 1:
            # æ²¡æœ‰é‡å¤ï¼Œç›´æ¥è¿”å›
            return content

        # æå–æ‰€æœ‰<think>å†…å®¹
        pattern = r'<think>(.*?)</think>'
        matches = re.findall(pattern, content, re.DOTALL)

        if len(matches) > 1:
            logger.info(f"Merging {len(matches)} thinking sections")

            # åˆå¹¶æ‰€æœ‰æ€è€ƒå†…å®¹
            merged_thinking = "\n\n".join(match.strip() for match in matches if match.strip())

            # ç§»é™¤æ‰€æœ‰<think>æ ‡ç­¾
            content_without_think = re.sub(pattern, '', content, flags=re.DOTALL)

            # é‡æ–°ç»„è£…ï¼Œåªä¿ç•™ä¸€ç»„<think>æ ‡ç­¾
            if merged_thinking:
                return f"<think>\n{merged_thinking}\n</think>\n\n{content_without_think.strip()}"
            else:
                return content_without_think.strip()

        return content

    @classmethod
    def extract_sections(cls, content: str) -> Tuple[Optional[str], str]:
        """
        æå–æ€è€ƒéƒ¨åˆ†å’Œç­”æ¡ˆéƒ¨åˆ†

        Returns:
            (thinking_content, answer_content)
        """
        # å…ˆæ¸…ç†é‡å¤æ ‡ç­¾
        content = cls.clean_duplicate_think_tags(content)

        # æå–æ€è€ƒå†…å®¹
        pattern = r'<think>(.*?)</think>'
        match = re.search(pattern, content, re.DOTALL)

        if match:
            thinking = match.group(1).strip()
            answer = re.sub(pattern, '', content, flags=re.DOTALL).strip()
            return thinking, answer

        return None, content

    @classmethod
    def should_include_thinking(cls, content: str, include_thinking: bool = True) -> str:
        """
        æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦åŒ…å«æ€è€ƒå†…å®¹
        """
        if not include_thinking:
            thinking, answer = cls.extract_sections(content)
            return answer
        return content

    @classmethod
    def format_for_display(cls, content: str, format_type: str = "default") -> str:
        """
        æ ¼å¼åŒ–è¾“å‡ºç”¨äºå±•ç¤º

        Args:
            content: åŸå§‹å†…å®¹
            format_type: æ ¼å¼ç±»å‹
                - "default": ä¿æŒåŸæ ·
                - "markdown": è½¬æ¢ä¸ºMarkdownæ ¼å¼
                - "separate": åˆ†ç¦»æ€è€ƒå’Œç­”æ¡ˆ
        """
        content = cls.clean_duplicate_think_tags(content)

        if format_type == "markdown":
            # å°†<think>æ ‡ç­¾è½¬æ¢ä¸ºMarkdownæ ¼å¼
            content = content.replace("<think>", "### ğŸ¤” æ€è€ƒè¿‡ç¨‹\n\n")
            content = content.replace("</think>", "\n\n---\n\n### ğŸ’¡ ç­”æ¡ˆ\n\n")
            return content

        elif format_type == "separate":
            thinking, answer = cls.extract_sections(content)
            result = ""
            if thinking:
                result += f"ã€æ€è€ƒè¿‡ç¨‹ã€‘\n{thinking}\n\n"
            result += f"ã€æœ€ç»ˆç­”æ¡ˆã€‘\n{answer}"
            return result

        return content


class StreamProcessor:
    """å¤„ç†æµå¼è¾“å‡º"""

    def __init__(self):
        self.buffer = ""
        self.in_think_tag = False
        self.think_tag_count = 0
        self.first_think_content = []
        self.second_think_content = []
        self.final_content = []

    def process_chunk(self, chunk: str) -> str:
        """
        å®æ—¶å¤„ç†æµå¼chunkï¼Œé¿å…é‡å¤çš„thinkæ ‡ç­¾
        """
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.buffer += chunk

        # æ£€æµ‹<think>æ ‡ç­¾
        if "<think>" in chunk:
            self.think_tag_count += 1
            if self.think_tag_count > 1:
                # å¿½ç•¥ç¬¬äºŒä¸ª<think>æ ‡ç­¾
                return ""
            self.in_think_tag = True
            return chunk

        if "</think>" in chunk:
            if self.think_tag_count > 1:
                # å¿½ç•¥å¤šä½™çš„</think>æ ‡ç­¾
                self.in_think_tag = False
                return ""
            self.in_think_tag = False
            return chunk

        # å¦‚æœåœ¨ç¬¬äºŒä¸ªthinkæ ‡ç­¾å†…ï¼Œæš‚å­˜å†…å®¹
        if self.in_think_tag and self.think_tag_count > 1:
            self.second_think_content.append(chunk)
            return ""  # ä¸è¾“å‡º

        return chunk

    def get_final_content(self) -> str:
        """è·å–æœ€ç»ˆå¤„ç†åçš„å†…å®¹"""
        # å¦‚æœæœ‰ç¬¬äºŒä¸ªthinkå†…å®¹ï¼Œåˆå¹¶åˆ°ç¬¬ä¸€ä¸ª
        if self.second_think_content:
            # é‡æ–°ç»„è£…å†…å®¹
            return ThinkTagProcessor.clean_duplicate_think_tags(self.buffer)
        return self.buffer